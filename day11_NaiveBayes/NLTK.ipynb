{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756a76b4-e907-409e-bbf5-caa60c7ebb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6629bb1-66d5-451f-86af-dd9428b60167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d041711b-2093-4501-8876-a942f48c87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95044486-feb3-4a15-b38c-eb1c55e0e68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16996499-452f-4ed3-a725-bbe40db26c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = brown.sents(categories=[\"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50dee2a8-3aa6-4ec5-96fe-545303bb9fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not the noblest performance we have heard him play , or the most spacious , or even the most eloquent .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27119648-01fc-4e3b-a836-c7bc055f3585",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27e266e6-388f-4c1e-905f-2fa1b3de4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19670d77-e593-4ab6-81c6-cecc59bf8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\" It was a very good movie. The cast was amazing and I liked the story.\n",
    "I went to the movie hall to see it.\n",
    "\"\"\"\n",
    "\n",
    "sentence = \"Code for Cause is too OP kunal@codeforcause.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e375f0af-6dec-423e-898f-626c1fb204be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' It was a very good movie.', 'The cast was amazing and I liked the story.', 'I went to the movie hall to see it.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = sent_tokenize(document)\n",
    "print(sents)\n",
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee627729-38e3-43f3-819d-69a457b63fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Code', 'for', 'Cause', 'is', 'too', 'OP', 'kunal', '@', 'codeforcause.org']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sentence) # also break down special characters\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541b431-d9b3-4724-ab3f-7660a320af0a",
   "metadata": {},
   "source": [
    "#### Tokenization using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccd210ca-4e85-4c52-91f6-1deb0f33bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "611c0163-1042-4fc2-a569-d8f24b2f4417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Code', 'for', 'Cause', 'is', 'too', 'OP', 'kunal@codeforcause.org']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('[a-zA-Z@.]+')\n",
    "useful = tokenizer.tokenize(sentence)\n",
    "print(useful)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418afe5f-d133-475e-8b93-c8e76999c272",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f6a1dc5-2a05-4e80-9ded-97643eb45460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b6e880c-4352-4c39-be93-a8a81cba0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e0f74a3-5dce-469f-a8ac-fe533f0ec2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e110c663-b69d-4003-b23b-579dddbe5594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'not', 'a', 'very', 'good', 'cricket', 'player']\n"
     ]
    }
   ],
   "source": [
    "text = \"i am not a very good cricket player\".split()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6cbb47ad-5fd8-4676-9a0d-2c3715534a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stoprwords(text, stopwords):\n",
    "    useful = [w for w in text if w not in stopwords]\n",
    "    return useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a700c40-06d7-4d77-acdd-a6d1740d730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_words = remove_stoprwords(text, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ba0267b-9249-473b-a4c3-fea886e02b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'cricket', 'player']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16e5af-f817-47c7-956a-a7b688c9c92f",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "151fda20-ec37-4dbd-8c33-a99519a7469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk provides us: Porter, Snowball, Lancaster stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00ac264d-6f48-4244-9c80-0d0bf28fc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4aec22a0-6827-4f8a-bef9-a0ae84500526",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bb0efcd-0eba-4939-88e6-a09d19b16e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laugh'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('laughing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30408182-55ab-41e4-a2b3-26151057e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowballStemmer = Multilingul, supports other langs also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a4cb1-799e-4408-acdb-e3c6dff126a0",
   "metadata": {},
   "source": [
    "## Building our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8636306a-a51e-4f3f-b6a7-25104dc68eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Dan Morgan told himself he would forget Ann Turner.',\n",
    "    'Sometimes he woke up in the middle of the night thinking of Ann , and then could not get back to sleep .',\n",
    "    'His plans and dreams had revolved around her so much and for so long that now he felt as if he had nothing .',\n",
    "    'He found that if he was tired enough at night , he went to sleep simply because he was too exhausted to stay awake .'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7cd2a0ab-45c4-4e0c-880c-16a7714732de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "206db055-a89e-4d1e-af55-b400d46a847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccd97e9d-7dec-4133-a9a9-93c5cf91af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorised corpus\n",
    "vc = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24e6431e-e069-4fcc-9b11-97e933ce3687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1]\n",
      " [1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 2 0 0\n",
      "  0 1 0 1 0 0 2 1 1 0 1 0 0 0 1 0 0 1 0]\n",
      " [2 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 2 2 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1 1\n",
      "  0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 4 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  1 1 0 0 1 1 0 0 0 1 2 0 1 0 0 2 1 0 0]]\n",
      "{'dan': 9, 'morgan': 27, 'told': 47, 'himself': 21, 'he': 19, 'would': 54, 'forget': 15, 'ann': 1, 'turner': 49, 'sometimes': 39, 'woke': 53, 'up': 50, 'in': 24, 'the': 42, 'middle': 26, 'of': 33, 'night': 29, 'thinking': 44, 'and': 0, 'then': 43, 'could': 8, 'not': 30, 'get': 17, 'back': 6, 'to': 46, 'sleep': 37, 'his': 22, 'plans': 34, 'dreams': 10, 'had': 18, 'revolved': 35, 'around': 2, 'her': 20, 'so': 38, 'much': 28, 'for': 14, 'long': 25, 'that': 41, 'now': 32, 'felt': 13, 'as': 3, 'if': 23, 'nothing': 31, 'found': 16, 'was': 51, 'tired': 45, 'enough': 11, 'at': 4, 'went': 52, 'simply': 36, 'because': 7, 'too': 48, 'exhausted': 12, 'stay': 40, 'awake': 5}\n"
     ]
    }
   ],
   "source": [
    "vc = vc.toarray()\n",
    "print(vc)\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3db3d4bb-3012-426d-aea5-772d062826d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02d16e4d-227d-4afb-a040-663a22f4480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(cv.vocabulary_))\n",
    "# i.e it has 55 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e60d4adc-459b-4582-82c2-5184bd7207ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 55\n"
     ]
    }
   ],
   "source": [
    "print(len(vc[0]),len(vc[1]))\n",
    "# all sentences has been changed to numbers with fixed number of features (55 here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5654f-c45e-46e4-ae7c-ac021664f7d1",
   "metadata": {},
   "source": [
    "#### building vocabulary after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ad5454a-8943-431b-8281-cb9dfb6225a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTokenizer(document):\n",
    "    words = tokenizer.tokenize(document.lower())\n",
    "    # remove the stopwords\n",
    "    words = remove_stoprwords(words, sw)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "09c42662-9194-4f63-a81a-a908d9166745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myTokenizer('this is a random text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c625726e-89ff-4fa1-9ad4-7108f57b9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=myTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3430abc8-f778-4ec7-9ff3-0f4c55976bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e4b040b7-d55d-4481-93c5-e924159da64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1]\n",
      " [1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "deee2fac-b12f-4dbf-ab7a-8c2db4edb8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vc[0])\n",
    "# after removing stop words length reduced from 55 to 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8fbcd192-d9b0-44d5-ba4f-915790dc30e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dan': 6, 'morgan': 16, 'told': 28, 'would': 32, 'forget': 11, 'ann': 1, 'turner.': 29, 'sometimes': 24, 'woke': 31, 'middle': 15, 'night': 18, 'thinking': 26, 'could': 5, 'get': 13, 'back': 4, 'sleep': 23, '.': 0, 'plans': 20, 'dreams': 7, 'revolved': 21, 'around': 2, 'much': 17, 'long': 14, 'felt': 10, 'nothing': 19, 'found': 12, 'tired': 27, 'enough': 8, 'went': 30, 'simply': 22, 'exhausted': 9, 'stay': 25, 'awake': 3}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06517c9-309a-4789-bbbc-9c4e5dec294c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913cf0f-77c6-4ed4-a2a4-1f3ad4d95986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfe297-faa4-489a-af61-744ad0e9a69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
